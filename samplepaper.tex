% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
\usepackage{helvet,times,courier}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\renewcommand{\topfraction}{1}
\renewcommand{\bottomfraction}{1}
% \renewcommand{\textfraction}{-0.1}
\addtolength{\textfloatsep}{-5ex}

\begin{document}
%
\title{Job Shop Scheduling with Multi-shot ASP}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Mohammed M. S. El-Kholany% \inst{1}
\and Martin Gebser}% \inst{1,2}}
%
\authorrunning{M.M.S. El-Kholany, M. Gebser}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Alpen-Adria-Universität Klagenfurt, Austria
% \and
%            Technische Universität Graz, Austria% \\
% \email{\{mohammed.el-kholany,martin.gebser\}@aau.at}
}
%
\maketitle              % typeset the header of the contribution
%
\section{Introduction}
The job shop scheduling problem consists of many jobs that must be processed by a set of machines.
It is one of the most complicated combinatorial optimization problems~\cite{lenstra1979computational}. However, in the literature, there are relatively few studies that focus on large-scale job shop scheduling. A rolling horizon approach has been proposed in \cite{singer2001decomposition}. It divides the problem into sub-problems (time windows) and solves each sub-problem using a shift bottleneck heuristic while minimizing the total weighted tardiness. A decomposition heuristic based on multi-bottleneck machines was proposed in \cite{zhai2014decomposition}, where each sub-problem was solved by a genetic algorithm. In this study, we investigate another decomposition method, balancing the number of operations per time window. 

\section{Approach}

The main idea of our proposed method is to split the set of all operations into time windows based on the earliest starting time for each operation, given by the sum of processing times of predecessor operations belonging to the same job.
That is, each job is a sequence of operations, all of which could be processed at their respective earliest starting time if the machine to use is free.
However, machines may be occupied by operations of other jobs,
so that the earliest starting time merely provides a lower bound on the actual starting time
of an operation.
%
% The operations with the minimum estimated starting time will be assigned firstly to the Time Window. If two operations or more have the same estimated starting time, the operation with longer processing time will have a higher priority to be assigned firstly. In case the processing time is equal, the operation that has earlier order in its job will have a higher priority. If the order of the operations is the same, the operation that belongs to the smaller job number will have a higher priority.

Given a job shop scheduling instance with $n$ operations, ordered by their earliest starting times, and a number $m$ of time windows,
the $i$-th time window for $1\leq i\leq m$
includes the operations at positions from
$(i-1) * \lceil n/m \rceil + 1$ to
$\min\{i * \lceil n/m \rceil, n\}$ in the order
by earliest starting times.
This static approach makes sure that the number of operations per time window is balanced,
amounting to at most $\lceil n/m \rceil$ operations and less for the 
last time window in case $n$ is not a multiple of $m$.
%
% The operations are assigned to the first Time Window until the maximum available number of operations, and then the rest are assigned to the next Time Windows.
%
After this decomposition, we schedule operations time window wise,
using the multi-shot Answer Set Programming (ASP; \cite{lifschitz1999answer})
system \textit{clingo}[DL] \cite{janhunen2017clingo},
an extension of \textit{clingo} \cite{gebser2019multi} with difference constraints.

We performed experiments with job shop scheduling instances of different size \cite{taillard1993benchmarks,storer1992new}, where the numbers of jobs and machines range from 30 to 100 or 10 to 20, respectively, using between 1 and 10 time windows, as indicated in the first column of Table~\ref{tab:Table01}.
The second column provides averages for compared features, including the makespan to minimize, runtime in seconds, and number of interrupted calls, over ten instances per size,
except for just five instances each in two groups
with 50 jobs and 10 machines,
denoted by 50$\times$10(e) and 50$\times$10(h),
as \cite{storer1992new} noted a subdivision into easy/hard instances.
% 
% The rest of the columns shows groups of instances with different size except for columns 5 and 6, which have the same size. It should be split because it is noticed in \cite{storer1992new} as Easy and Hard instances.

% Each group in the table represents a set of instances of the same size. The numbers in the table are the average of makespan, CPU time, and the number of interrupted calls of instances per group. From Table \ref{tab:Table01}, we can see that the values of makespan with one Time Window are the best in most cases. Increasing Time Windows provide solutions in a shorter time, but the quality of solutions is getting worse. However, when the problem size increased, the values of makespan of more Time Windows are better than those with one Time Window. For example, the makespan value of the instances 100 X 20 with one Time Windows is 46786.1. However, with three and four Time Windows are 7002.6 and 6964.4 respectively. In a conclusion, decomposing the whole problem into sub-problems has a positive impact especially when the problem size is large.
%
Considering the number of interrupted calls when using just 1 or 2 time windows,
the entries 1.0 or 2.0, respectively, tell us that all calls during multi-shot
solving time out, which means that finding (and proving) an optimal schedule was infeasible
within the allotted 1000.0 seconds of runtime, divided evenly among all time windows.
One should note that each job is a sequence of 10 operations, so that the number of
operations to schedule amounts to 300 for the 10 instances in the smallest group, i.e., 30$\times$15.
% For this group, the timeouts disappear with 10 time windows, where 30 operations per window
% need to be scheduled optimally within 100.0 seconds of runtime for each.
For this group,
the average runtime drops from 1000.0 to just \textbf{2.6} seconds when switching from
1 to 10 time windows,
while the average makespan of best schedules found increases from \textbf{2144.7} to 2679.1.
In general, looking at the smallest average makespans and runtimes, highlighted in boldface,
we see that fewer or more time windows, respectively, are advantageous.
For the 100$\times$20 group, % where all calls time out,
the average makespan is best with 4 time windows, which indicates noticeable benefits due to
decomposing large instances.

\begin{table}[t]
    \caption{Results for job shop scheduling instances with different numbers of time windows\label{tab:Table01}}%
%    \mbox{~}\hfill
%    \resizebox{0.8\textwidth}{!}{%
%    \begin{minipage}{\textwidth}
    \centering
    \begin{tabular}{l l r r r r r r r r r}
    \hline
%       & {}        & \multicolumn{6}{c}{Group of Instances}  \\
    Window(s) & Comparison & 30$\times$15 & 30$\times$20  & 50$\times$10(e) & 50$\times$10(h) & 50$\times$15 & 50$\times$20 & 100$\times$20 \\
                     
    \hline\\[-2.75mm]
    1                & Makespan             & \textbf{2144.7}	& 2450.0   & \textbf{3035.4}	     & \textbf{4462.6}	   & 3542.1	 & 3879.4  & 46786.1 \\
                     & CPU(Sec)             & 1000.0	& 1000.0   & 1000.0	     & 1000.0	   & 1000.0	 & 1000.0  & 1000.0 \\
                     & Interrupted Calls    & 1.0	    & 1.0      & 1.0	     & 1.0	       & 1.0	 & 1.0     & 1.0 \\[1.5mm]
                     
    2                & Makespan             & 2228.9	& \textbf{2345.0}   & 3167.8	     & 5001.8	   & \textbf{3524.8}	 & \textbf{3540.8}  & 23977.5 \\
                     & CPU(Sec)             & 1000.0	    & 1000.0	   & 1000.0	     & 1000.0	   & 1000.0	 & 1000.0  & 1000.0 \\
                     & Interrupted Calls    & 2.0	    & 2.0      & 2.0	     & 2.0	       & 2.0	 & 2.0     & 2.0 \\[1.5mm]
                     
    3                & Makespan             & 2396.7	& 2542.1   & 3439.6	     & 4914.0	   & 3621.5	 & 3605.7  & 7002.6 \\
                     & CPU(Sec)             & 921.5	    & 804.8    & 1000.0	     & 1000.0	   & 1000.0	 & 1000.0  & 1000.0 \\
                     & Interrupted Calls    & 2.7	    & 2.2      & 3.0	     & 3.0	       & 3.0	 & 3.0     & 3.0 \\[1.5mm]
                     
    4                & Makespan             & 2481.0	& 2632.9   & 3556.4	     & 5483.4	   & 3870.0	 & 3918.6  & \textbf{6964.4} \\
                     & CPU(Sec)             & 345.9	    & 482.9	   & 1000.0	     & 1000.0	   & 1000.0	 & 1000.0   & 1000.0 \\
                     & Interrupted Calls    & 1.1	    & 1.7      & 4.0	     & 4.0	       & 4.0	 & 4.0     & 4.0 \\[1.5mm]
                     
    5                & Makespan             & 2537.9	& 2750.1   & 3572.4	     & 5598.2	   & 3908.1	 & 4006.3  & 7094.9 \\
                     & CPU(Sec)             & 190.5	    & 233.3	   & 952.3	     & 1000.0	   & 978.8	 & 974.3   & 1000.0 \\
                     & Interrupted Calls    & 0.7	    & 1.1      & 4.6	     & 5.0	       & 4.8	 & 4.8     & 5.0 \\[1.5mm]
                     
    6                & Makespan             & 2600.3	& 2856.4   & 3803.0	     & 5742.4	   & 4043.5	 & 4116.5  & 7357.9 \\
                     & CPU(Sec)             & 75.9	    & 94.1	   & 781.6	     & 1000.0	   & 919.6	 & 855.4   & 1000.0 \\
                     & Interrupted Calls    & 0.3	    & 0.3      & 4.2	     & 6.0	       & 5.4	 & 4.9     & 6.0 \\[1.5mm]
                     
    7                & Makespan             & 2659.7	& 2868.6   & 3669.6	     & 5612.4	   & 4064.3	 & 4144.1  & 7519.4 \\
                     & CPU(Sec)             & 16.5	    & 6.4	   & 656.1	     & 885.3	   & 706.4	 & 668.0   & 1000.0 \\
                     & Interrupted Calls    & 0.0	    & 0.0      & 4.6	     & 6.2	       & 4.1	 & 3.8     & 7.0 \\[1.5mm]
                     
    8                & Makespan             & 2656.8	& 2938.8   & 3764.8	     & 5790.6	   & 4269.0	 & 4228.0  & 7587.0 \\
                     & CPU(Sec)             & 40.5	    & 41.3	   & 355.5	     & 911.4	   & 522.6	 & 420.8   & 1000.0 \\
                     & Interrupted Calls    & 0.3	    & 0.1      & 2.4	     & 7.2	       & 3.5	 & 2.6     & 8.0 \\[1.5mm]
                     
    9                & Makespan             & 2642.9	& 2946.0   & 3691.0	     & 5546.8	   & 4146.4	 & 4366.2  & 7681.6 \\
                     & CPU(Sec)             & 13.2	    & \textbf{3.1}	   & 308.4	     & 854.1	   & 321.9	 & 392.9   & 1000.0 \\
                     & Interrupted Calls    & 0.1	    & 0.0      & 2.2	     & 7.6	       & 2.5	 & 2.9     & 9.0 \\[1.5mm]
                     
    10               & Makespan             & 2679.1	& 2982.2   & 3619.0	     & 5804.8	   & 4127.3	 & 4397.1  & 7925.6 \\
                     & CPU(Sec)             & \textbf{2.6}	    & 6.3	   & \textbf{209.4}	     & \textbf{772.6}	   & \textbf{239.7}	 & \textbf{245.2}   & 1000.0 \\
                     & Interrupted Calls    & 0.0	    & 0.0      & 1.8	     & 7.4	       & 1.9	 & 2.0     & 10.0 \\
    \\[-2.75mm]
    \hline
    \end{tabular}
   % }
%    \end{minipage}
% }
%    \hfill\hfill\mbox{~}
\end{table}

\bibliographystyle{splncs04}
\bibliography{References.bib}

% \newpage
% \appendix
% \section{Appendix}

\end{document}
